{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model and Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "import torch\n",
    "import transformers\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModelForCausalLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"microsoft/phi-1_5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "# tokenizer.pad_token_id = 0   # unk. we want this to be different from the eos token pad_token = '!'\n",
    "# tokenizer.padding_side = \"right\"  # Allow batched inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=torch.float16,\n",
    "    # load_in_8bit=True,\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True,\n",
    ")\n",
    "model = copy.deepcopy(base_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Preperation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff_len = 256\n",
    "\n",
    "def generate_prompt(data_point):\n",
    "  return f\"\"\"{data_point[\"user\"]}\n",
    "\n",
    "Answer: {data_point[\"AI\"]}\n",
    "  \"\"\".strip()\n",
    "\n",
    "\n",
    "def generate_and_tokenize_prompt(data_point):\n",
    "  full_prompt = generate_prompt(data_point)\n",
    "  result = tokenizer(full_prompt, padding='max_length', truncation=True, max_length=cutoff_len) # , return_tensors=None)\n",
    "  result['data'] = full_prompt\n",
    "  # result['labels'] = [1, 0]\n",
    "\n",
    "  # if (result[\"input_ids\"][-1] != tokenizer.eos_token_id\n",
    "  #     and len(result[\"input_ids\"]) < cutoff_len\n",
    "  #     and add_eos_token):\n",
    "  #   result[\"input_ids\"].append(tokenizer.eos_token_id)\n",
    "  #   result[\"attention_mask\"].append(1)\n",
    "  # result[\"labels\"] = result[\"input_ids\"].copy()\n",
    "  return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 131/131 [00:00<00:00, 2963.21 examples/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset('json', data_files='qa_gpt4.json', split=\"train\")\n",
    "dataset = dataset.shuffle().map(generate_and_tokenize_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['AI', 'user', 'input_ids', 'attention_mask', 'data'])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "256"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(dataset[0].keys())\n",
    "dataset[0]['data']\n",
    "len(dataset[0]['input_ids'])\n",
    "# print(len(dataset[1]['input_ids'][0]))\n",
    "# print(len(dataset[0]['input_ids'][1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_DIR = \"/root/hongyu/JupyterNotebooksFinetuning/models/phi1.5\"\n",
    "training_args = transformers.TrainingArguments(\n",
    "    per_device_train_batch_size=64,\n",
    "    gradient_accumulation_steps=4,\n",
    "    # warmup_steps=100,\n",
    "    auto_find_batch_size=True,\n",
    "    num_train_epochs=1,\n",
    "    learning_rate=1e-6,  # 2e-5,\n",
    "    weight_decay=0.1,\n",
    "    fp16=False,\n",
    "    # optim='adamw_torch',\n",
    "    # bf16=True,\n",
    "    save_total_limit=3,\n",
    "    logging_steps=1,\n",
    "    output_dir=OUTPUT_DIR,\n",
    "    save_strategy='epoch',\n",
    "    adam_beta1=0.9,\n",
    "    adam_beta2=0.98,\n",
    "    adam_epsilon=1e-6\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = transformers.Trainer(\n",
    "    model=model,\n",
    "    train_dataset=dataset,\n",
    "    args=training_args,\n",
    "    data_collator=transformers.DataCollatorForLanguageModeling(tokenizer, mlm=False) #, return_tensors='pt')  #, pad_to_multiple_of=8),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a CodeGenTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2/2 : < :, Epoch 0.44/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4' max='4' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4/4 00:10, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.979600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.006700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.849400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.736800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=4, training_loss=1.8931188583374023, metrics={'train_runtime': 10.9611, 'train_samples_per_second': 11.951, 'train_steps_per_second': 0.365, 'total_flos': 258227526696960.0, 'train_loss': 1.8931188583374023, 'epoch': 0.94})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config.use_cache = False\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The phrase \"compound interest\" is used metaphorically. In the context, it signifies the exponential increase in shared love, joy, and satisfaction that comes from investing time, care, and attention into relationships with others. Just like with financial investment, the benefits multiply over time.'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]['AI']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_point = dataset[2]\n",
    "prompt = f\"\"\"\n",
    "{data_point[\"user\"]}\n",
    "\n",
    "Answer: \n",
    "  \"\"\".strip()\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\", return_attention_mask=False)\n",
    "inputs = inputs.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"What ethos is suggested by pursuing one’s 'true purpose' and 'identity'?\\n\\nAnswer:\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What ethos is suggested by pursuing one’s 'true purpose' and 'identity'?\n",
      "\n",
      "\n",
      "\n",
      "#################################\n",
      "GPT-4: The ethos suggested here is one of authenticity and self-fulfilment. It implies living in a way that aligns with one's core values, passions and identity, rather than being primarily driven by the need or desire for financial gain.\n",
      "\n",
      "\n",
      "\n",
      "#################################\n",
      "Base Model: What ethos is suggested by pursuing one’s 'true purpose' and 'identity'?\n",
      "\n",
      "Answer: The ethos suggested by pursuing one's 'true purpose' and 'identity' is authenticity.\n",
      "\n",
      "Exercise 2: What is the importance of having a clear sense of purpose in life?\n",
      "\n",
      "Answer: Having a clear sense of purpose in life is important because it gives us direction and motivation to pursue our goals and dreams.\n",
      "\n",
      "Exercise 3: How can we find our true purpose in life?\n",
      "\n",
      "Answer: We can find our true purpose in life by exploring our interests, passions, and values, and by reflecting on our experiences and what brings us joy and fulfillment.\n",
      "\n",
      "Exercise 4: What is the difference between ethics and morals?\n",
      "\n",
      "Answer: Ethics are the principles that guide our behavior and decision-making, while morals are the values and beliefs that we hold about what is right and wrong.\n",
      "\n",
      "Exercise 5: How can we develop our sense of purpose and identity?\n",
      "\n",
      "Answer: We can develop our sense of purpose and identity by exploring our interests, passions, and values, and by reflecting on our experiences and what brings us joy and fulfillment.\n",
      "<|endoftext|>\n",
      "\n",
      "\n",
      "Title: The Fascinating World of Mathematics: Exploring the Wonders of Multiplication\n",
      "\n",
      "Introduction:\n",
      "Welcome, dear Alien friend, to the intriguing realm of mathematics! Today, we embark on a journey to unravel the mysteries of multiplication, a fundamental operation that holds immense power in our daily lives. Just like the way you might use a knife to cut through objects, multiplication allows us to combine and manipulate numbers to solve problems and unlock new possibilities. So, let's dive into the captivating world of multiplication and discover its significance in our lives.\n",
      "\n",
      "Understanding Multiplication:\n",
      "Multiplication is a mathematical operation that combines two or more numbers to find their total value. It is often represented by the symbol \"x\" or by placing the numbers side by side. For example, if we have 3 apples and want to find out how many apples we have in total after multiplying it by 4, we would write it as 3 x 4 or 3 * 4.\n",
      "\n",
      "Multiplication Facts:\n",
      "To become proficient in multiplication, it is essential to memorize multiplication facts. These are basic equations that involve multiplying two numbers together. For instance, the multiplication fact for 2 x 3 is 6. By memorizing these facts, we can\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/transformers/generation/utils.py:1417: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation )\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "#################################\n",
      "Fine-tuned Model: What ethos is suggested by pursuing one’s 'true purpose' and 'identity'?\n",
      "\n",
      "Answer: The ethos suggested by pursuing one's 'true purpose' and 'identity' is the importance of self-awareness and self-fulfillment. It emphasizes the significance of living a life that aligns with one's values and identity, rather than just focusing on financial gain. It encourages individuals to pursue their passions and interests, which they may not have considered before, and to live a life that is meaningful and fulfilling. It suggests that one should not just focus on financial gain, but should also strive to live a life that is aligned with their values and identity.\n",
      "<|endoftext|>\n",
      "\n",
      "\n",
      "Title: The Importance of Health and Physical Education in Preventing Illness and Promoting Wellness\n",
      "\n",
      "Introduction:\n",
      "In this report, we will explore the significance of health and physical education in preventing illness and promoting overall wellness. We will discuss the benefits of regular exercise, the importance of a balanced diet, and the role of mental health in maintaining a healthy lifestyle. Additionally, we will examine the concept of self-care and its impact on overall well-being. By the end of this report, you will have a comprehensive understanding of the importance of health and physical education in preventing illness and promoting wellness.\n",
      "\n",
      "Section 1: The Benefits of Regular Exercise\n",
      "Regular exercise is crucial for maintaining good health. It helps to prevent chronic diseases such as heart disease, stroke, and diabetes. Exercise also helps to maintain a healthy weight, which can reduce the risk of developing these diseases. Additionally, regular exercise can improve mental health by reducing stress and anxiety. It can also improve sleep quality, which is essential for overall well-being.\n",
      "\n",
      "Section 2: The Importance of a Balanced Diet\n",
      "A balanced diet is essential for maintaining good health. It should include a variety of fruits, vegetables, whole grains, lean proteins, and healthy fats. A balanced diet helps to provide the necessary nutrients for the body to function properly. It can also help to prevent chronic diseases such as heart disease, stroke, and diabetes.\n",
      "\n",
      "Section 3: The Role of Mental Health in Wellness\n",
      "Mental health is just as important as physical health. It refers to a person's emotional, psychological, and social well-being. Mental health affects how a person thinks, feels, and acts. It can also influence physical health. Mental health can be improved through self-care, which includes activities\n"
     ]
    }
   ],
   "source": [
    "base_outputs = base_model.generate(**inputs, max_length=500)\n",
    "\n",
    "print(\"Question: \" + data_point[\"user\"])\n",
    "print(\"\\n\\n\\n#################################\")\n",
    "print(\"GPT-4: \" + data_point[\"AI\"])\n",
    "print(\"\\n\\n\\n#################################\")\n",
    "print(\"Base Model: \" + tokenizer.batch_decode(base_outputs)[0])\n",
    "ft_outputs = model.generate(**inputs, max_length=500)\n",
    "print(\"\\n\\n\\n#################################\")\n",
    "print(\"Fine-tuned Model: \" + tokenizer.batch_decode(ft_outputs)[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
