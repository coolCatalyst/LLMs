# -*- coding: utf-8 -*-
"""Falcon.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1DEcWRrkgsfaDVqo-I-wvrQ2i8BoqJg43
"""

!pip install transformers
!pip install datasets
!pip install torchvision
!pip install numpy
!pip install torch
!pip install einops

import torch
from transformers import AutoModelForQuestionAnswering, AutoTokenizer, DataCollatorWithPadding, Trainer, TrainingArguments
from datasets import load_dataset

model_name = "tiiuae/falcon-7b"
dataset_name = "truthful_qa"
dataset_config = "generation"
model = AutoModelForQuestionAnswering.from_pretrained(
    model_name,
    trust_remote_code=True
)

tokenizer = AutoTokenizer.from_pretrained(model_name)

dataset = load_dataset(dataset_name, dataset_config)

def prepare_train_features(examples):
    tokenized_examples = tokenizer(
        examples["question"],
        truncation=True,
        padding="max_length"
    )
    return tokenized_examples

tokenized_datasets = dataset.map(prepare_train_features, batched=True)
data_collator = DataCollatorWithPadding(tokenizer=tokenizer)

training_args = TrainingArguments(
    output_dir="./results",
    learning_rate=5e-5,
    per_device_train_batch_size=16,
    per_device_eval_batch_size=16,
    num_train_epochs=3,
    weight_decay=0.01,
)

trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=tokenized_datasets["train"],
    eval_dataset=tokenized_datasets["validation"],
    data_collator=data_collator,
    tokenizer=tokenizer
)

trainer.train()
trainer.evaluate()

